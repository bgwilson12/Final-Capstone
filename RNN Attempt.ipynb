{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# # pickle.dump(essays_lsa, open('../essays_lsa.pkl', 'wb'))\n",
    "# essays_lsa = pickle.load(open('../essays_lsa.pkl', 'rb'))\n",
    "# df_features = pickle.load(open('../df_features.pkl', 'rb'))\n",
    "\n",
    "# X_train_lsa, X_test_lsa, y_train_lsa, y_test_lsa = train_test_split(essays_lsa,\n",
    "#                                                                     df_features.student,\n",
    "#                                                                     test_size=0.2,\n",
    "#                                                                     stratify=df_features.student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we are. Nothing from sklearn was able to make any kind of good predictions on the dataset, so now we are moving on to TensorFlow. We are going to build out a Recurrent Neural Network that takes in each sentence as a datapoint. Each sentence will be a sequence of words represented by an integer, and punctuation will be included in the representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>joined</th>\n",
       "      <th>student</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nursing</td>\n",
       "      <td>Total Word Count: This report has been prepare...</td>\n",
       "      <td>student</td>\n",
       "      <td>(Total, Word, Count, :, This, report, has, bee...</td>\n",
       "      <td>total word count : this report have be prepare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nursing</td>\n",
       "      <td>Leadership has been described as \"a relational...</td>\n",
       "      <td>student</td>\n",
       "      <td>(Leadership, has, been, described, as, \", a, r...</td>\n",
       "      <td>leadership have be describe as \" a relational ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nursing</td>\n",
       "      <td>Depression among pregnant adolescents as well ...</td>\n",
       "      <td>student</td>\n",
       "      <td>(Depression, among, pregnant, adolescents, as,...</td>\n",
       "      <td>depression among pregnant adolescent as well a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nursing</td>\n",
       "      <td>Davidson, E., Daly, J., Brady, R. &amp; Higgins, P...</td>\n",
       "      <td>student</td>\n",
       "      <td>(Davidson, ,, E., ,, Daly, ,, J., ,, Brady, ,,...</td>\n",
       "      <td>davidson , e. , daly , j. , brady , r. &amp; higgi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nursing</td>\n",
       "      <td>Idiopathic pulmonary fibrosis (IPF) is a devas...</td>\n",
       "      <td>student</td>\n",
       "      <td>(Idiopathic, pulmonary, fibrosis, (, IPF, ), i...</td>\n",
       "      <td>idiopathic pulmonary fibrosis ( ipf ) be a dev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject                                             joined  student  \\\n",
       "0  nursing  Total Word Count: This report has been prepare...  student   \n",
       "1  nursing  Leadership has been described as \"a relational...  student   \n",
       "2  nursing  Depression among pregnant adolescents as well ...  student   \n",
       "3  nursing  Davidson, E., Daly, J., Brady, R. & Higgins, P...  student   \n",
       "4  nursing  Idiopathic pulmonary fibrosis (IPF) is a devas...  student   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  (Total, Word, Count, :, This, report, has, bee...   \n",
       "1  (Leadership, has, been, described, as, \", a, r...   \n",
       "2  (Depression, among, pregnant, adolescents, as,...   \n",
       "3  (Davidson, ,, E., ,, Daly, ,, J., ,, Brady, ,,...   \n",
       "4  (Idiopathic, pulmonary, fibrosis, (, IPF, ), i...   \n",
       "\n",
       "                                              lemmas  \n",
       "0  total word count : this report have be prepare...  \n",
       "1  leadership have be describe as \" a relational ...  \n",
       "2  depression among pregnant adolescent as well a...  \n",
       "3  davidson , e. , daly , j. , brady , r. & higgi...  \n",
       "4  idiopathic pulmonary fibrosis ( ipf ) be a dev...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9013c6498f35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#             rnn_df.loc[j, 'sent_len'] = len(span)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#             j += 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mrnn_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../rnn_df.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mrnn_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "rnn_df = pd.DataFrame(columns=['student', 'sentence', 'doc_no', 'sent_len'])\n",
    "j = 0\n",
    "max_length = 50\n",
    "# for i, doc in enumerate(df_features.tokens):\n",
    "#     for span in doc.sents:\n",
    "#         if (len(span) <= max_length) and (len(span) >= 4):\n",
    "#             rnn_df.loc[j, 'sentence'] = span\n",
    "#             rnn_df.loc[j, 'student'] = df_features.loc[i, 'student']\n",
    "#             rnn_df.loc[j, 'doc_no'] = i\n",
    "#             rnn_df.loc[j, 'sent_len'] = len(span)\n",
    "#             j += 1\n",
    "rnn_df = pickle.load(open('../rnn_df.pkl', 'rb'))\n",
    "rnn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ca832340f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For some reason plugging in the df was making the kernel hang. \n",
    "# Might have something to do with seaborn, Stack Overflow mentioned that\n",
    "list_of_lengths = rnn_df.sent_len.tolist()\n",
    "plt.hist(list_of_lengths)\n",
    "plt.title('Length of Sentences')\n",
    "plt.xlabel('Length of Sentence')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the lengths of the sequences we are going to feed into our RNN. We don't want them to be much longer than 50 because then we run into the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=TreebankWordTokenizer().tokenize\n",
    "                            ).fit(df_features.joined)\n",
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 74666\n",
      "Usable sentences: 74666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>doc_no</th>\n",
       "      <th>target</th>\n",
       "      <th>sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53832.0</td>\n",
       "      <td>57582.0</td>\n",
       "      <td>16771.0</td>\n",
       "      <td>6446.0</td>\n",
       "      <td>53276.0</td>\n",
       "      <td>45952.0</td>\n",
       "      <td>26995.0</td>\n",
       "      <td>10833.0</td>\n",
       "      <td>42962.0</td>\n",
       "      <td>24320.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>student</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36738.0</td>\n",
       "      <td>54382.0</td>\n",
       "      <td>56784.0</td>\n",
       "      <td>6541.0</td>\n",
       "      <td>5555.0</td>\n",
       "      <td>57942.0</td>\n",
       "      <td>38945.0</td>\n",
       "      <td>32412.0</td>\n",
       "      <td>57221.0</td>\n",
       "      <td>26587.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>student</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53022.0</td>\n",
       "      <td>18939.0</td>\n",
       "      <td>56784.0</td>\n",
       "      <td>32581.0</td>\n",
       "      <td>45348.0</td>\n",
       "      <td>53624.0</td>\n",
       "      <td>43574.0</td>\n",
       "      <td>33051.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>6541.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>student</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19444.0</td>\n",
       "      <td>53669.0</td>\n",
       "      <td>57461.0</td>\n",
       "      <td>14058.0</td>\n",
       "      <td>15564.0</td>\n",
       "      <td>27418.0</td>\n",
       "      <td>11586.0</td>\n",
       "      <td>43415.0</td>\n",
       "      <td>13096.0</td>\n",
       "      <td>879.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>student</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48937.0</td>\n",
       "      <td>26587.0</td>\n",
       "      <td>33855.0</td>\n",
       "      <td>57198.0</td>\n",
       "      <td>11586.0</td>\n",
       "      <td>16771.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>33855.0</td>\n",
       "      <td>41882.0</td>\n",
       "      <td>16771.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>58503.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>student</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3        4        5        6        7  \\\n",
       "0  53832.0  57582.0  16771.0   6446.0  53276.0  45952.0  26995.0  10833.0   \n",
       "1  36738.0  54382.0  56784.0   6541.0   5555.0  57942.0  38945.0  32412.0   \n",
       "2  53022.0  18939.0  56784.0  32581.0  45348.0  53624.0  43574.0  33051.0   \n",
       "3  19444.0  53669.0  57461.0  14058.0  15564.0  27418.0  11586.0  43415.0   \n",
       "4  48937.0  26587.0  33855.0  57198.0  11586.0  16771.0    763.0  33855.0   \n",
       "\n",
       "         8        9    ...          43       44       45       46       47  \\\n",
       "0  42962.0  24320.0    ...     58503.0  58503.0  58503.0  58503.0  58503.0   \n",
       "1  57221.0  26587.0    ...     58503.0  58503.0  58503.0  58503.0  58503.0   \n",
       "2    763.0   6541.0    ...     58503.0  58503.0  58503.0  58503.0  58503.0   \n",
       "3  13096.0    879.0    ...     58503.0  58503.0  58503.0  58503.0  58503.0   \n",
       "4  41882.0  16771.0    ...     58503.0  58503.0  58503.0  58503.0  58503.0   \n",
       "\n",
       "        48       49  doc_no   target  sent_len  \n",
       "0  58503.0  58503.0     0.0  student      32.0  \n",
       "1  58503.0  58503.0     0.0  student      23.0  \n",
       "2  58503.0  58503.0     0.0  student      31.0  \n",
       "3  58503.0  58503.0     0.0  student      10.0  \n",
       "4  58503.0  58503.0     0.0  student      22.0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rnn_features = pd.DataFrame(columns=[])\n",
    "\n",
    "# translate_dict = vectorizer.vocabulary_\n",
    "# vocab_length = len(translate_dict)\n",
    "\n",
    "# # Adding a few unicode strings to our dict\n",
    "# translate_dict[u\"\\u2019s\"] = vocab_length  + 1      # Curly single quote, 's\n",
    "# translate_dict[u\"\\u00B0\"] = vocab_length   + 2      # Degree, as in celsius\n",
    "# translate_dict[u\"n\\u2019t\"] = vocab_length + 3      # n't\n",
    "# translate_dict[u\"\\u0022\"] = vocab_length   + 4      # double straight quote \"\n",
    "\n",
    "\n",
    "\n",
    "for i, span in enumerate(rnn_df.sentence):\n",
    "    span_length = len(span)\n",
    "    for j in range(max_length+1):\n",
    "        if j < span_length:\n",
    "            try:\n",
    "                rnn_features.loc[i, j] = translate_dict[span[j].lower_]\n",
    "            except:\n",
    "                if len(span[j]) > 10:\n",
    "                    rnn_features.loc[i, j] = None\n",
    "                else:\n",
    "                    rnn_features.loc[i, j] = vocab_length + 5\n",
    "        elif j <= 49:\n",
    "            rnn_features.loc[i, j] = vocab_length + 6\n",
    "        else:\n",
    "            rnn_features.loc[i, j] = rnn_df.doc_no[i]\n",
    "            rnn_features.loc[i, j+1] = rnn_df.student[i]\n",
    "            rnn_features.loc[i, j+2] = rnn_df.sent_len[i]\n",
    "    if i % 5000 == 0:\n",
    "        print('Working on row: {}'.format(i))\n",
    "\n",
    "max_length = 50\n",
    "rnn_features = pickle.load(open('../rnn_features.pkl', 'rb'))\n",
    "\n",
    "rnn_features.rename({max_length:'doc_no', max_length+1:'target', max_length+2:'sent_len'}, axis=1, inplace=True)\n",
    "print('Total sentences:', len(rnn_features))\n",
    "rnn_features.dropna(inplace=True)\n",
    "rnn_features.reset_index(inplace=True, drop=True)\n",
    "print('Usable sentences:', len(rnn_features))\n",
    "rnn_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import winsound\n",
    "# frequency = np.random.randint(2000, 4000, 50)  # Set Frequency \n",
    "# duration = 25  # Set Duration To 1000 ms == 1 second\n",
    "# for each in frequency:\n",
    "#     winsound.Beep(each, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(rnn_features, open('../rnn_features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bretw\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ====================\n",
    "#  TOY DATA GENERATOR\n",
    "# ====================\n",
    "\n",
    "class SequenceData(object):\n",
    "    \"\"\" Generate sequence of data with dynamic length.\n",
    "    This class generate samples for training:\n",
    "    - Class 0: linear sequences (i.e. [0, 1, 2, 3,...])\n",
    "    - Class 1: random sequences (i.e. [1, 3, 10, 7,...])\n",
    "\n",
    "    NOTICE:\n",
    "    We have to pad each sequence to reach 'max_seq_len' for TensorFlow\n",
    "    consistency (we cannot feed a numpy array with inconsistent\n",
    "    dimensions). The dynamic calculation will then be perform thanks to\n",
    "    'seqlen' attribute that records every actual sequence length.\n",
    "    \"\"\"\n",
    "    def __init__(self, df_features):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.seqlen = []\n",
    "        n_samples = len(df_features)\n",
    "        \n",
    "        for i, row in enumerate(df_features.iloc[:, 0:50].values):\n",
    "            row_list = []\n",
    "            for component in row:\n",
    "                row_list.append([int(component)])\n",
    "            self.data.append(row_list)\n",
    "            \n",
    "            if df_features.iloc[i, 51] == 'student':\n",
    "                self.labels.append([1., 0.])\n",
    "            else:\n",
    "                self.labels.append([0., 1.])\n",
    "                \n",
    "            # Monitor sequence length for TensorFlow dynamic calculation\n",
    "            self.seqlen.append(df_features.iloc[i, 52])\n",
    "        self.batch_id = 0\n",
    "\n",
    "    def next(self, batch_size):\n",
    "        \"\"\" Return a batch of data. When dataset end is reached, start over.\n",
    "        \"\"\"\n",
    "        if self.batch_id == len(self.data):\n",
    "            self.batch_id = 0\n",
    "        batch_data = (self.data[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        self.batch_id = min(self.batch_id + batch_size, len(self.data))\n",
    "        return batch_data, batch_labels, batch_seqlen\n",
    "\n",
    "# Test it out\n",
    "# this = SequenceData(rnn_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(rnn_features, test_size = 0.2, stratify=rnn_features.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ==========\n",
    "#   MODEL\n",
    "# ==========\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "seq_max_len = 50 # Sequence max length\n",
    "n_hidden = 64 # hidden layer num of features\n",
    "n_classes = 2 # linear sequence or not\n",
    "\n",
    "new_data = True\n",
    "if new_data:\n",
    "    trainset = SequenceData(X_train)\n",
    "    testset = SequenceData(X_test)\n",
    "else:\n",
    "    trainset = pickle.load(open('../trainset_tf.pkl', 'rb'))\n",
    "    testset = pickle.load(open('../testset_tf.pkl', 'rb'))\n",
    "    \n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, seq_max_len, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "# A placeholder for indicating each sequence length\n",
    "seqlen = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(trainset, open('../trainset_tf.pkl', 'wb'))\n",
    "# pickle.dump(testset, open('../testset_tf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dynamicRNN(x, seqlen, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    \n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, seq_max_len, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # Get lstm cell output, providing 'sequence_length' will perform dynamic\n",
    "    # calculation.\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32,\n",
    "                                sequence_length=seqlen)\n",
    "\n",
    "    # When performing dynamic calculation, we must retrieve the last\n",
    "    # dynamically computed output, i.e., if a sequence length is 10, we need\n",
    "    # to retrieve the 10th output.\n",
    "    # However TensorFlow doesn't support advanced indexing yet, so we build\n",
    "    # a custom op that for each sample in batch size, get its length and\n",
    "    # get the corresponding relevant output.\n",
    "\n",
    "    # 'outputs' is a list of output at every timestep, we pack them in a Tensor\n",
    "    # and change back dimension to [batch_size, n_step, n_input]\n",
    "    outputs = tf.stack(outputs)\n",
    "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "\n",
    "    # Hack to build the indexing and retrieve the right output.\n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    # Start indices for each sample\n",
    "    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n",
    "    # Indexing\n",
    "    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n",
    "\n",
    "    # Linear activation, using outputs computed above\n",
    "    return tf.matmul(outputs, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bretw\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "pred = dynamicRNN(x, seqlen, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(targets=y, logits=pred, pos_weight=2))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 0.746188, Training Accuracy= 0.92188\n",
      "Step 200, Minibatch Loss= 0.298234, Training Accuracy= 0.95312\n",
      "Step 400, Minibatch Loss= 0.510836, Training Accuracy= 0.88281\n",
      "Step 600, Minibatch Loss= 0.384593, Training Accuracy= 0.92188\n",
      "Step 800, Minibatch Loss= 0.597474, Training Accuracy= 0.85156\n",
      "Step 1000, Minibatch Loss= 0.393634, Training Accuracy= 0.91406\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       seqlen: batch_seqlen})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch accuracy & loss\n",
    "            acc, loss = sess.run([accuracy, cost], feed_dict={x: batch_x, y: batch_y,\n",
    "                                                seqlen: batch_seqlen})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_data = testset.data\n",
    "    test_label = testset.labels\n",
    "    test_seqlen = testset.seqlen\n",
    "    y_final_pred = sess.run(pred, feed_dict={x: test_data, y: test_label,\n",
    "                                             seqlen: test_seqlen})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.126489 , -1.7164415],\n",
       "       [ 3.1264887, -1.716441 ],\n",
       "       [ 3.126489 , -1.7164415],\n",
       "       ...,\n",
       "       [ 3.126489 , -1.7164415],\n",
       "       [ 3.1303556, -1.4746436],\n",
       "       [ 3.1264842, -1.7164391]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_ = np.argmax(y_final_pred, axis=1)\n",
    "y_pred_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(testset.labels[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
